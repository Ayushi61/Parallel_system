1) Your lake.log timings and kernel timing statistics (stdout) for each optimization
--Answer----
  
	 
	With  optimization 1:-- Using open acc Naive method
	running ./lake_opti with (512 x 512) grid, until 4.000000, with 1 threads
	Initialization took 0.010458 seconds
	Simulation took 64.791603 seconds
	Init+Simulation took 64.802061 seconds
	
	With optimization 2- Inner loop for , outer loop parallel
	running ./lake_opti with (512 x 512) grid, until 4.000000, with 1 threads
	Initialization took 0.008263 seconds
	Simulation took 7.772665 seconds
	Init+Simulation took 7.780928 seconds

	
	With optimization 3-- Data copy outside while loop and caching data , and parallel for on outer loop
	running ./lake_opti with (512 x 512) grid, until 4.000000, with 1 threads
	Initialization took 0.007973 seconds
	Simulation took 6.925619 seconds
	Init+Simulation took 6.933592 seconds

	

	
	With optimization 4: - memcopy parallelizatiion
	running ./lake_opti with (512 x 512) grid, until 4.000000, with 1 threads
	Initialization took 0.010430 seconds
	Simulation took 1.319201 seconds
	Init+Simulation took 1.329631 seconds

	

2) Discuss each optimization (one at a time) in detail
--Answer----
	
	1) With open acc Naive , having data copy and loop parallelized with accelerator , optimizes the code about 3X times - takes 64 seconds
	2)Scheduling inner loop with for and parallel outer loop - takes around 3 seconds- 
	3) To further optimize, the data copy region is pulled out of while loop and placed outside while, segregating openacc data directive and loop . Use outer loop for parallel for, 
	This gives a considerable speedup, as now the data is not copied everytime in the loop . Also the cache is used to bring all the stencil points to the cache. takes 6 secons
	
	4) The memcpy for swapping uc,un u0 is parallelized to give better optimixation. This gives around 50x speedup. 
	
	
3) The effect of the problem size (smaller vs. larger grids, short vs. longer simulation times)
--Answer--- 
	Smaller problem size- -- Optimizations seen were minimal- as the number of data points are less, and with increase in data points serial complexity increases exponentially. Therefore, parallelizatiion speedup effects are notices only when number of data points are high. 
	Larger grids, show comparitively higher degree of optimizations, and time is reduced to a great extent.
	
4) Where your biggest optimization came from (eg thread scheduling? memory management? screaming at the screen louder?)
--Answer-- 
	Biggest optimization came from 
	1) thread scheduling using parallel for on the outer loop.  around 10x
	2) memory management-- Copying the data to memory only once. -additional 5x over 10x, 
	total= 50x.

5) Possible improvements in the code, etc.
---Answer--- 
	The code can be further optimized by using blocking technique and getting data to be used in current iteration closer to the cache.
