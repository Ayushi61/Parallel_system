2020-04-04 18:56:19,439 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Running Spark version 1.6.1
2020-04-04 18:56:20,047 WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-04 18:56:20,261 INFO  [main] spark.SecurityManager (Logging.scala:logInfo(58)) - Changing view acls to: arajend4
2020-04-04 18:56:20,262 INFO  [main] spark.SecurityManager (Logging.scala:logInfo(58)) - Changing modify acls to: arajend4
2020-04-04 18:56:20,263 INFO  [main] spark.SecurityManager (Logging.scala:logInfo(58)) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(arajend4); users with modify permissions: Set(arajend4)
2020-04-04 18:56:20,880 INFO  [main] util.Utils (Logging.scala:logInfo(58)) - Successfully started service 'sparkDriver' on port 40355.
2020-04-04 18:56:21,416 INFO  [sparkDriverActorSystem-akka.actor.default-dispatcher-2] slf4j.Slf4jLogger (Slf4jLogger.scala:applyOrElse(80)) - Slf4jLogger started
2020-04-04 18:56:21,484 INFO  [sparkDriverActorSystem-akka.actor.default-dispatcher-2] Remoting (Slf4jLogger.scala:apply$mcV$sp(74)) - Starting remoting
2020-04-04 18:56:21,697 INFO  [sparkDriverActorSystem-akka.actor.default-dispatcher-2] Remoting (Slf4jLogger.scala:apply$mcV$sp(74)) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.4.1.31:44937]
2020-04-04 18:56:21,704 INFO  [main] util.Utils (Logging.scala:logInfo(58)) - Successfully started service 'sparkDriverActorSystem' on port 44937.
2020-04-04 18:56:21,719 INFO  [main] spark.SparkEnv (Logging.scala:logInfo(58)) - Registering MapOutputTracker
2020-04-04 18:56:21,740 INFO  [main] spark.SparkEnv (Logging.scala:logInfo(58)) - Registering BlockManagerMaster
2020-04-04 18:56:21,757 INFO  [main] storage.DiskBlockManager (Logging.scala:logInfo(58)) - Created local directory at /tmp/blockmgr-9a09f98a-f4dc-4e33-8648-877c36f520a1
2020-04-04 18:56:21,780 INFO  [main] storage.MemoryStore (Logging.scala:logInfo(58)) - MemoryStore started with capacity 511.1 MB
2020-04-04 18:56:21,874 INFO  [main] spark.SparkEnv (Logging.scala:logInfo(58)) - Registering OutputCommitCoordinator
2020-04-04 18:56:22,133 INFO  [main] server.Server (Server.java:doStart(272)) - jetty-8.y.z-SNAPSHOT
2020-04-04 18:56:22,195 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(338)) - Started SelectChannelConnector@0.0.0.0:4040
2020-04-04 18:56:22,196 INFO  [main] util.Utils (Logging.scala:logInfo(58)) - Successfully started service 'SparkUI' on port 4040.
2020-04-04 18:56:22,199 INFO  [main] ui.SparkUI (Logging.scala:logInfo(58)) - Started SparkUI at http://10.4.1.31:4040
2020-04-04 18:56:22,250 INFO  [main] spark.HttpFileServer (Logging.scala:logInfo(58)) - HTTP File server directory is /tmp/spark-afba352f-d46f-49ad-a180-2e060112b88f/httpd-9de3de33-cdf3-48ab-a841-b7224e39f6bd
2020-04-04 18:56:22,255 INFO  [main] spark.HttpServer (Logging.scala:logInfo(58)) - Starting HTTP Server
2020-04-04 18:56:22,268 INFO  [main] server.Server (Server.java:doStart(272)) - jetty-8.y.z-SNAPSHOT
2020-04-04 18:56:22,275 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(338)) - Started SocketConnector@0.0.0.0:42737
2020-04-04 18:56:22,276 INFO  [main] util.Utils (Logging.scala:logInfo(58)) - Successfully started service 'HTTP file server' on port 42737.
2020-04-04 18:56:22,297 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Added JAR file:/home/arajend4/hw4/Parallel_system/hw5/p1/TFICF/TFICF.jar at http://10.4.1.31:42737/jars/TFICF.jar with timestamp 1586040982296
2020-04-04 18:56:22,379 INFO  [main] executor.Executor (Logging.scala:logInfo(58)) - Starting executor ID driver on host localhost
2020-04-04 18:56:22,410 INFO  [main] util.Utils (Logging.scala:logInfo(58)) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41699.
2020-04-04 18:56:22,411 INFO  [main] netty.NettyBlockTransferService (Logging.scala:logInfo(58)) - Server created on 41699
2020-04-04 18:56:22,412 INFO  [main] storage.BlockManagerMaster (Logging.scala:logInfo(58)) - Trying to register BlockManager
2020-04-04 18:56:22,419 INFO  [dispatcher-event-loop-10] storage.BlockManagerMasterEndpoint (Logging.scala:logInfo(58)) - Registering block manager localhost:41699 with 511.1 MB RAM, BlockManagerId(driver, localhost, 41699)
2020-04-04 18:56:22,423 INFO  [main] storage.BlockManagerMaster (Logging.scala:logInfo(58)) - Registered BlockManager
2020-04-04 18:56:24,161 INFO  [main] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 268.7 KB)
2020-04-04 18:56:24,221 INFO  [main] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.0 KB, free 290.8 KB)
2020-04-04 18:56:24,226 INFO  [dispatcher-event-loop-12] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_0_piece0 in memory on localhost:41699 (size: 22.0 KB, free: 511.1 MB)
2020-04-04 18:56:24,231 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 0 from wholeTextFiles at TFICF.java:33
2020-04-04 18:56:24,499 INFO  [main] input.FileInputFormat (FileInputFormat.java:listStatus(283)) - Total input paths to process : 3
2020-04-04 18:56:24,513 INFO  [main] input.FileInputFormat (FileInputFormat.java:listStatus(283)) - Total input paths to process : 3
2020-04-04 18:56:24,520 INFO  [main] input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 33
2020-04-04 18:56:24,539 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Starting job: count at TFICF.java:36
2020-04-04 18:56:24,569 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Got job 0 (count at TFICF.java:36) with 2 output partitions
2020-04-04 18:56:24,570 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Final stage: ResultStage 0 (count at TFICF.java:36)
2020-04-04 18:56:24,570 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Parents of final stage: List()
2020-04-04 18:56:24,572 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Missing parents: List()
2020-04-04 18:56:24,583 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ResultStage 0 (input MapPartitionsRDD[1] at wholeTextFiles at TFICF.java:33), which has no missing parents
2020-04-04 18:56:24,664 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_1 stored as values in memory (estimated size 2.5 KB, free 293.2 KB)
2020-04-04 18:56:24,668 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1527.0 B, free 294.7 KB)
2020-04-04 18:56:24,670 INFO  [dispatcher-event-loop-13] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_1_piece0 in memory on localhost:41699 (size: 1527.0 B, free: 511.1 MB)
2020-04-04 18:56:24,672 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:24,677 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 2 missing tasks from ResultStage 0 (input MapPartitionsRDD[1] at wholeTextFiles at TFICF.java:33)
2020-04-04 18:56:24,680 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 0.0 with 2 tasks
2020-04-04 18:56:24,739 INFO  [dispatcher-event-loop-14] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 0.0 (TID 0, localhost, partition 1,PROCESS_LOCAL, 2255 bytes)
2020-04-04 18:56:24,745 INFO  [dispatcher-event-loop-14] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 0.0 (TID 1, localhost, partition 0,ANY, 2312 bytes)
2020-04-04 18:56:24,755 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 0.0 (TID 1)
2020-04-04 18:56:24,755 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 0.0 (TID 0)
2020-04-04 18:56:24,770 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Fetching http://10.4.1.31:42737/jars/TFICF.jar with timestamp 1586040982296
2020-04-04 18:56:24,892 INFO  [Executor task launch worker-1] util.Utils (Logging.scala:logInfo(58)) - Fetching http://10.4.1.31:42737/jars/TFICF.jar to /tmp/spark-afba352f-d46f-49ad-a180-2e060112b88f/userFiles-e063a7f0-011e-49bf-bc85-31dd5a010bb3/fetchFileTemp8196102173644893961.tmp
2020-04-04 18:56:24,909 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Adding file:/tmp/spark-afba352f-d46f-49ad-a180-2e060112b88f/userFiles-e063a7f0-011e-49bf-bc85-31dd5a010bb3/TFICF.jar to class loader
2020-04-04 18:56:24,954 INFO  [Executor task launch worker-0] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc3:0+33
2020-04-04 18:56:24,954 INFO  [Executor task launch worker-1] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc1:0+34,/user/arajend4/input/doc2:0+39
2020-04-04 18:56:25,198 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 0.0 (TID 0). 2082 bytes result sent to driver
2020-04-04 18:56:25,213 INFO  [task-result-getter-0] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 0.0 (TID 0) in 494 ms on localhost (1/2)
2020-04-04 18:56:25,231 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 0.0 (TID 1). 2082 bytes result sent to driver
2020-04-04 18:56:25,240 INFO  [task-result-getter-1] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 0.0 (TID 1) in 498 ms on localhost (2/2)
2020-04-04 18:56:25,242 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ResultStage 0 (count at TFICF.java:36) finished in 0.543 s
2020-04-04 18:56:25,243 INFO  [task-result-getter-1] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-04-04 18:56:25,254 INFO  [main] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Job 0 finished: count at TFICF.java:36, took 0.714326 s
2020-04-04 18:56:25,281 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Starting job: collect at TFICF.java:41
2020-04-04 18:56:25,283 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Got job 1 (collect at TFICF.java:41) with 2 output partitions
2020-04-04 18:56:25,284 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Final stage: ResultStage 1 (collect at TFICF.java:41)
2020-04-04 18:56:25,284 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Parents of final stage: List()
2020-04-04 18:56:25,284 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Missing parents: List()
2020-04-04 18:56:25,285 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ResultStage 1 (input MapPartitionsRDD[1] at wholeTextFiles at TFICF.java:33), which has no missing parents
2020-04-04 18:56:25,289 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 297.3 KB)
2020-04-04 18:56:25,295 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1566.0 B, free 298.8 KB)
2020-04-04 18:56:25,297 INFO  [dispatcher-event-loop-3] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_2_piece0 in memory on localhost:41699 (size: 1566.0 B, free: 511.1 MB)
2020-04-04 18:56:25,298 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:25,298 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 2 missing tasks from ResultStage 1 (input MapPartitionsRDD[1] at wholeTextFiles at TFICF.java:33)
2020-04-04 18:56:25,298 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 1.0 with 2 tasks
2020-04-04 18:56:25,310 INFO  [dispatcher-event-loop-4] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 1.0 (TID 2, localhost, partition 1,PROCESS_LOCAL, 2255 bytes)
2020-04-04 18:56:25,312 INFO  [dispatcher-event-loop-4] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 1.0 (TID 3, localhost, partition 0,ANY, 2312 bytes)
2020-04-04 18:56:25,313 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 1.0 (TID 3)
2020-04-04 18:56:25,313 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 1.0 (TID 2)
2020-04-04 18:56:25,325 INFO  [Executor task launch worker-0] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc1:0+34,/user/arajend4/input/doc2:0+39
2020-04-04 18:56:25,329 INFO  [Executor task launch worker-1] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc3:0+33
2020-04-04 18:56:25,395 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 1.0 (TID 2). 2184 bytes result sent to driver
2020-04-04 18:56:25,410 INFO  [task-result-getter-2] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 1.0 (TID 2) in 108 ms on localhost (1/2)
2020-04-04 18:56:25,457 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 1.0 (TID 3). 2279 bytes result sent to driver
2020-04-04 18:56:25,467 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ResultStage 1 (collect at TFICF.java:41) finished in 0.167 s
2020-04-04 18:56:25,469 INFO  [main] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Job 1 finished: collect at TFICF.java:41, took 0.187126 s
2020-04-04 18:56:25,471 INFO  [task-result-getter-3] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 1.0 (TID 3) in 153 ms on localhost (2/2)
2020-04-04 18:56:25,471 INFO  [task-result-getter-3] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 1.0, whose tasks have all completed, from pool 
------Contents of filesRDD------
(hdfs://c30:9000/user/arajend4/input/doc1) , (Lorem ipsum dolor ipsum sit ipsum)
(hdfs://c30:9000/user/arajend4/input/doc2) , (Vituperata incorrupte at ipsum pro quo)
(hdfs://c30:9000/user/arajend4/input/doc3) , (Has persius disputationi id simul)
--------------------------------
2020-04-04 18:56:25,495 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Starting job: collect at TFICF.java:80
2020-04-04 18:56:25,497 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Got job 2 (collect at TFICF.java:80) with 2 output partitions
2020-04-04 18:56:25,497 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Final stage: ResultStage 2 (collect at TFICF.java:80)
2020-04-04 18:56:25,497 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Parents of final stage: List()
2020-04-04 18:56:25,498 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Missing parents: List()
2020-04-04 18:56:25,498 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ResultStage 2 (MapPartitionsRDD[2] at flatMapToPair at TFICF.java:58), which has no missing parents
2020-04-04 18:56:25,505 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_3 stored as values in memory (estimated size 2.9 KB, free 301.8 KB)
2020-04-04 18:56:25,510 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1732.0 B, free 303.5 KB)
2020-04-04 18:56:25,511 INFO  [dispatcher-event-loop-9] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_3_piece0 in memory on localhost:41699 (size: 1732.0 B, free: 511.1 MB)
2020-04-04 18:56:25,512 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:25,513 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[2] at flatMapToPair at TFICF.java:58)
2020-04-04 18:56:25,514 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 2.0 with 2 tasks
2020-04-04 18:56:25,517 INFO  [dispatcher-event-loop-10] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 2.0 (TID 4, localhost, partition 1,PROCESS_LOCAL, 2255 bytes)
2020-04-04 18:56:25,521 INFO  [dispatcher-event-loop-10] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 2.0 (TID 5, localhost, partition 0,ANY, 2312 bytes)
2020-04-04 18:56:25,522 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 2.0 (TID 4)
2020-04-04 18:56:25,522 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 2.0 (TID 5)
2020-04-04 18:56:25,531 INFO  [Executor task launch worker-1] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc1:0+34,/user/arajend4/input/doc2:0+39
2020-04-04 18:56:25,533 INFO  [Executor task launch worker-0] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc3:0+33
2020-04-04 18:56:25,617 INFO  [dispatcher-event-loop-0] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Removed broadcast_2_piece0 on localhost:41699 in memory (size: 1566.0 B, free: 511.1 MB)
2020-04-04 18:56:25,625 INFO  [Spark Context Cleaner] spark.ContextCleaner (Logging.scala:logInfo(58)) - Cleaned accumulator 2
2020-04-04 18:56:25,628 INFO  [dispatcher-event-loop-2] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Removed broadcast_1_piece0 on localhost:41699 in memory (size: 1527.0 B, free: 511.1 MB)
2020-04-04 18:56:25,630 INFO  [Spark Context Cleaner] spark.ContextCleaner (Logging.scala:logInfo(58)) - Cleaned accumulator 1
2020-04-04 18:56:25,637 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 2.0 (TID 4). 2298 bytes result sent to driver
2020-04-04 18:56:25,641 INFO  [task-result-getter-0] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 2.0 (TID 4) in 124 ms on localhost (1/2)
2020-04-04 18:56:25,676 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 2.0 (TID 5). 2463 bytes result sent to driver
2020-04-04 18:56:25,680 INFO  [task-result-getter-1] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 2.0 (TID 5) in 162 ms on localhost (2/2)
2020-04-04 18:56:25,681 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ResultStage 2 (collect at TFICF.java:80) finished in 0.165 s
2020-04-04 18:56:25,681 INFO  [task-result-getter-1] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-04-04 18:56:25,682 INFO  [main] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Job 2 finished: collect at TFICF.java:80, took 0.185968 s
------Contents of wordsRDD------
(Lorem@doc1) , (6)
(ipsum@doc1) , (6)
(dolor@doc1) , (6)
(ipsum@doc1) , (6)
(sit@doc1) , (6)
(ipsum@doc1) , (6)
(Vituperata@doc2) , (6)
(incorrupte@doc2) , (6)
(at@doc2) , (6)
(ipsum@doc2) , (6)
(pro@doc2) , (6)
(quo@doc2) , (6)
(Has@doc3) , (5)
(persius@doc3) , (5)
(disputationi@doc3) , (5)
(id@doc3) , (5)
(simul@doc3) , (5)
--------------------------------
2020-04-04 18:56:25,736 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Starting job: collect at TFICF.java:128
2020-04-04 18:56:25,751 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Registering RDD 3 (mapValues at TFICF.java:96)
2020-04-04 18:56:25,752 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Got job 3 (collect at TFICF.java:128) with 2 output partitions
2020-04-04 18:56:25,752 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Final stage: ResultStage 4 (collect at TFICF.java:128)
2020-04-04 18:56:25,752 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Parents of final stage: List(ShuffleMapStage 3)
2020-04-04 18:56:25,752 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Missing parents: List(ShuffleMapStage 3)
2020-04-04 18:56:25,754 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ShuffleMapStage 3 (MapPartitionsRDD[3] at mapValues at TFICF.java:96), which has no missing parents
2020-04-04 18:56:25,764 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_4 stored as values in memory (estimated size 4.1 KB, free 299.4 KB)
2020-04-04 18:56:25,767 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 301.7 KB)
2020-04-04 18:56:25,768 INFO  [dispatcher-event-loop-6] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_4_piece0 in memory on localhost:41699 (size: 2.2 KB, free: 511.1 MB)
2020-04-04 18:56:25,769 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:25,772 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[3] at mapValues at TFICF.java:96)
2020-04-04 18:56:25,772 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 3.0 with 2 tasks
2020-04-04 18:56:25,778 INFO  [dispatcher-event-loop-5] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 3.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2244 bytes)
2020-04-04 18:56:25,782 INFO  [dispatcher-event-loop-5] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 3.0 (TID 7, localhost, partition 0,ANY, 2301 bytes)
2020-04-04 18:56:25,783 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 3.0 (TID 6)
2020-04-04 18:56:25,783 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 3.0 (TID 7)
2020-04-04 18:56:25,792 INFO  [Executor task launch worker-1] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc3:0+33
2020-04-04 18:56:25,811 INFO  [Executor task launch worker-0] rdd.WholeTextFileRDD (Logging.scala:logInfo(58)) - Input split: Paths:/user/arajend4/input/doc1:0+34,/user/arajend4/input/doc2:0+39
2020-04-04 18:56:25,893 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 3.0 (TID 6). 2254 bytes result sent to driver
2020-04-04 18:56:25,909 INFO  [task-result-getter-2] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 3.0 (TID 6) in 133 ms on localhost (1/2)
2020-04-04 18:56:25,914 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 3.0 (TID 7). 2254 bytes result sent to driver
2020-04-04 18:56:25,922 INFO  [task-result-getter-3] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 3.0 (TID 7) in 141 ms on localhost (2/2)
2020-04-04 18:56:25,922 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ShuffleMapStage 3 (mapValues at TFICF.java:96) finished in 0.149 s
2020-04-04 18:56:25,923 INFO  [task-result-getter-3] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020-04-04 18:56:25,924 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - looking for newly runnable stages
2020-04-04 18:56:25,925 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - running: Set()
2020-04-04 18:56:25,926 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - waiting: Set(ResultStage 4)
2020-04-04 18:56:25,926 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - failed: Set()
2020-04-04 18:56:25,928 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ResultStage 4 (ShuffledRDD[4] at reduceByKey at TFICF.java:106), which has no missing parents
2020-04-04 18:56:25,934 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_5 stored as values in memory (estimated size 2.9 KB, free 304.5 KB)
2020-04-04 18:56:25,937 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_5_piece0 stored as bytes in memory (estimated size 1728.0 B, free 306.2 KB)
2020-04-04 18:56:25,939 INFO  [dispatcher-event-loop-12] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_5_piece0 in memory on localhost:41699 (size: 1728.0 B, free: 511.1 MB)
2020-04-04 18:56:25,940 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:25,940 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 2 missing tasks from ResultStage 4 (ShuffledRDD[4] at reduceByKey at TFICF.java:106)
2020-04-04 18:56:25,941 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 4.0 with 2 tasks
2020-04-04 18:56:25,946 INFO  [dispatcher-event-loop-11] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 4.0 (TID 8, localhost, partition 0,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:25,947 INFO  [dispatcher-event-loop-11] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 4.0 (TID 9, localhost, partition 1,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:25,948 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 4.0 (TID 8)
2020-04-04 18:56:25,949 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 4.0 (TID 9)
2020-04-04 18:56:25,964 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:25,964 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:25,970 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 10 ms
2020-04-04 18:56:25,970 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 10 ms
2020-04-04 18:56:26,002 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 4.0 (TID 9). 1472 bytes result sent to driver
2020-04-04 18:56:26,002 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 4.0 (TID 8). 1351 bytes result sent to driver
2020-04-04 18:56:26,005 INFO  [task-result-getter-1] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 4.0 (TID 8) in 63 ms on localhost (1/2)
2020-04-04 18:56:26,006 INFO  [task-result-getter-0] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 4.0 (TID 9) in 59 ms on localhost (2/2)
2020-04-04 18:56:26,007 INFO  [task-result-getter-0] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2020-04-04 18:56:26,007 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ResultStage 4 (collect at TFICF.java:128) finished in 0.066 s
2020-04-04 18:56:26,008 INFO  [main] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Job 3 finished: collect at TFICF.java:128, took 0.272081 s
-------Contents of tfRDD--------
(Lorem@doc1) , (1/6)
(id@doc3) , (1/5)
(disputationi@doc3) , (1/5)
(ipsum@doc2) , (1/6)
(persius@doc3) , (1/5)
(incorrupte@doc2) , (1/6)
(ipsum@doc1) , (3/6)
(pro@doc2) , (1/6)
(Has@doc3) , (1/5)
(simul@doc3) , (1/5)
(dolor@doc1) , (1/6)
(sit@doc1) , (1/6)
(quo@doc2) , (1/6)
(at@doc2) , (1/6)
(Vituperata@doc2) , (1/6)
--------------------------------
2020-04-04 18:56:26,040 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Starting job: collect at TFICF.java:195
2020-04-04 18:56:26,047 INFO  [dag-scheduler-event-loop] spark.MapOutputTrackerMaster (Logging.scala:logInfo(58)) - Size of output statuses for shuffle 0 is 155 bytes
2020-04-04 18:56:26,051 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Registering RDD 5 (mapToPair at TFICF.java:145)
2020-04-04 18:56:26,052 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Got job 4 (collect at TFICF.java:195) with 2 output partitions
2020-04-04 18:56:26,053 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Final stage: ResultStage 7 (collect at TFICF.java:195)
2020-04-04 18:56:26,053 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Parents of final stage: List(ShuffleMapStage 6)
2020-04-04 18:56:26,053 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Missing parents: List(ShuffleMapStage 6)
2020-04-04 18:56:26,054 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at mapToPair at TFICF.java:145), which has no missing parents
2020-04-04 18:56:26,058 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 309.5 KB)
2020-04-04 18:56:26,062 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_6_piece0 stored as bytes in memory (estimated size 1962.0 B, free 311.4 KB)
2020-04-04 18:56:26,064 INFO  [dispatcher-event-loop-15] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_6_piece0 in memory on localhost:41699 (size: 1962.0 B, free: 511.1 MB)
2020-04-04 18:56:26,066 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:26,066 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at mapToPair at TFICF.java:145)
2020-04-04 18:56:26,066 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 6.0 with 2 tasks
2020-04-04 18:56:26,068 INFO  [dispatcher-event-loop-2] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 6.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1930 bytes)
2020-04-04 18:56:26,069 INFO  [dispatcher-event-loop-2] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 6.0 (TID 11, localhost, partition 1,NODE_LOCAL, 1930 bytes)
2020-04-04 18:56:26,069 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 6.0 (TID 11)
2020-04-04 18:56:26,069 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 6.0 (TID 10)
2020-04-04 18:56:26,076 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,076 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,076 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 1 ms
2020-04-04 18:56:26,076 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 1 ms
2020-04-04 18:56:26,085 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 6.0 (TID 10). 1375 bytes result sent to driver
2020-04-04 18:56:26,088 INFO  [task-result-getter-2] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 6.0 (TID 10) in 19 ms on localhost (1/2)
2020-04-04 18:56:26,089 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 6.0 (TID 11). 1375 bytes result sent to driver
2020-04-04 18:56:26,091 INFO  [task-result-getter-3] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 6.0 (TID 11) in 23 ms on localhost (2/2)
2020-04-04 18:56:26,092 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ShuffleMapStage 6 (mapToPair at TFICF.java:145) finished in 0.024 s
2020-04-04 18:56:26,092 INFO  [task-result-getter-3] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2020-04-04 18:56:26,092 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - looking for newly runnable stages
2020-04-04 18:56:26,093 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - running: Set()
2020-04-04 18:56:26,093 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - waiting: Set(ResultStage 7)
2020-04-04 18:56:26,093 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - failed: Set()
2020-04-04 18:56:26,095 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ResultStage 7 (MapPartitionsRDD[7] at flatMapToPair at TFICF.java:172), which has no missing parents
2020-04-04 18:56:26,098 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_7 stored as values in memory (estimated size 3.4 KB, free 314.8 KB)
2020-04-04 18:56:26,102 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2036.0 B, free 316.8 KB)
2020-04-04 18:56:26,104 INFO  [dispatcher-event-loop-7] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_7_piece0 in memory on localhost:41699 (size: 2036.0 B, free: 511.1 MB)
2020-04-04 18:56:26,105 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:26,106 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[7] at flatMapToPair at TFICF.java:172)
2020-04-04 18:56:26,106 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 7.0 with 2 tasks
2020-04-04 18:56:26,109 INFO  [dispatcher-event-loop-8] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 7.0 (TID 12, localhost, partition 0,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:26,110 INFO  [dispatcher-event-loop-8] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 7.0 (TID 13, localhost, partition 1,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:26,112 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 7.0 (TID 12)
2020-04-04 18:56:26,112 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 7.0 (TID 13)
2020-04-04 18:56:26,115 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,115 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 0 ms
2020-04-04 18:56:26,117 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,118 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 2 ms
2020-04-04 18:56:26,118 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 7.0 (TID 12). 1369 bytes result sent to driver
2020-04-04 18:56:26,121 INFO  [task-result-getter-1] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 7.0 (TID 12) in 12 ms on localhost (1/2)
2020-04-04 18:56:26,124 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 7.0 (TID 13). 1457 bytes result sent to driver
2020-04-04 18:56:26,133 INFO  [task-result-getter-0] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 7.0 (TID 13) in 23 ms on localhost (2/2)
2020-04-04 18:56:26,134 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ResultStage 7 (collect at TFICF.java:195) finished in 0.026 s
2020-04-04 18:56:26,134 INFO  [task-result-getter-0] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2020-04-04 18:56:26,135 INFO  [main] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Job 4 finished: collect at TFICF.java:195, took 0.094183 s
-------Contents of icfRDD-------
(simul@doc3) , (3/1)
(Has@doc3) , (3/1)
(sit@doc1) , (3/1)
(ipsum@doc2) , (3/2)
(ipsum@doc1) , (3/2)
(dolor@doc1) , (3/1)
(Vituperata@doc2) , (3/1)
(persius@doc3) , (3/1)
(pro@doc2) , (3/1)
(Lorem@doc1) , (3/1)
(quo@doc2) , (3/1)
(at@doc2) , (3/1)
(disputationi@doc3) , (3/1)
(incorrupte@doc2) , (3/1)
(id@doc3) , (3/1)
--------------------------------
2020-04-04 18:56:26,166 INFO  [main] spark.SparkContext (Logging.scala:logInfo(58)) - Starting job: collect at TFICF.java:268
2020-04-04 18:56:26,172 INFO  [dag-scheduler-event-loop] spark.MapOutputTrackerMaster (Logging.scala:logInfo(58)) - Size of output statuses for shuffle 0 is 155 bytes
2020-04-04 18:56:26,175 INFO  [dag-scheduler-event-loop] spark.MapOutputTrackerMaster (Logging.scala:logInfo(58)) - Size of output statuses for shuffle 1 is 155 bytes
2020-04-04 18:56:26,177 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Registering RDD 10 (union at TFICF.java:247)
2020-04-04 18:56:26,177 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Got job 5 (collect at TFICF.java:268) with 4 output partitions
2020-04-04 18:56:26,177 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Final stage: ResultStage 11 (collect at TFICF.java:268)
2020-04-04 18:56:26,178 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Parents of final stage: List(ShuffleMapStage 10)
2020-04-04 18:56:26,178 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Missing parents: List(ShuffleMapStage 10)
2020-04-04 18:56:26,179 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ShuffleMapStage 10 (UnionRDD[10] at union at TFICF.java:247), which has no missing parents
2020-04-04 18:56:26,193 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_8 stored as values in memory (estimated size 4.4 KB, free 321.2 KB)
2020-04-04 18:56:26,195 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 323.7 KB)
2020-04-04 18:56:26,196 INFO  [dispatcher-event-loop-13] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_8_piece0 in memory on localhost:41699 (size: 2.5 KB, free: 511.1 MB)
2020-04-04 18:56:26,197 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:26,198 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 4 missing tasks from ShuffleMapStage 10 (UnionRDD[10] at union at TFICF.java:247)
2020-04-04 18:56:26,200 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 10.0 with 4 tasks
2020-04-04 18:56:26,205 INFO  [dispatcher-event-loop-14] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 10.0 (TID 14, localhost, partition 0,NODE_LOCAL, 2039 bytes)
2020-04-04 18:56:26,207 INFO  [dispatcher-event-loop-14] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 10.0 (TID 15, localhost, partition 1,NODE_LOCAL, 2039 bytes)
2020-04-04 18:56:26,208 INFO  [dispatcher-event-loop-14] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 2.0 in stage 10.0 (TID 16, localhost, partition 2,NODE_LOCAL, 2039 bytes)
2020-04-04 18:56:26,208 INFO  [dispatcher-event-loop-14] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 3.0 in stage 10.0 (TID 17, localhost, partition 3,NODE_LOCAL, 2039 bytes)
2020-04-04 18:56:26,209 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 10.0 (TID 14)
2020-04-04 18:56:26,209 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 10.0 (TID 15)
2020-04-04 18:56:26,210 INFO  [Executor task launch worker-2] executor.Executor (Logging.scala:logInfo(58)) - Running task 2.0 in stage 10.0 (TID 16)
2020-04-04 18:56:26,220 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,221 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 1 ms
2020-04-04 18:56:26,222 INFO  [Executor task launch worker-3] executor.Executor (Logging.scala:logInfo(58)) - Running task 3.0 in stage 10.0 (TID 17)
2020-04-04 18:56:26,223 INFO  [Executor task launch worker-2] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,223 INFO  [Executor task launch worker-2] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 0 ms
2020-04-04 18:56:26,229 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,230 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 1 ms
2020-04-04 18:56:26,230 INFO  [Executor task launch worker-3] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 2 blocks
2020-04-04 18:56:26,231 INFO  [Executor task launch worker-3] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 1 ms
2020-04-04 18:56:26,232 INFO  [Executor task launch worker-2] executor.Executor (Logging.scala:logInfo(58)) - Finished task 2.0 in stage 10.0 (TID 16). 1377 bytes result sent to driver
2020-04-04 18:56:26,233 INFO  [task-result-getter-2] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 2.0 in stage 10.0 (TID 16) in 26 ms on localhost (1/4)
2020-04-04 18:56:26,235 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 10.0 (TID 15). 1377 bytes result sent to driver
2020-04-04 18:56:26,239 INFO  [task-result-getter-3] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 10.0 (TID 15) in 33 ms on localhost (2/4)
2020-04-04 18:56:26,240 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 10.0 (TID 14). 1377 bytes result sent to driver
2020-04-04 18:56:26,241 INFO  [task-result-getter-1] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 10.0 (TID 14) in 39 ms on localhost (3/4)
2020-04-04 18:56:26,248 INFO  [Executor task launch worker-3] executor.Executor (Logging.scala:logInfo(58)) - Finished task 3.0 in stage 10.0 (TID 17). 1377 bytes result sent to driver
2020-04-04 18:56:26,250 INFO  [task-result-getter-0] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 3.0 in stage 10.0 (TID 17) in 42 ms on localhost (4/4)
2020-04-04 18:56:26,250 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ShuffleMapStage 10 (union at TFICF.java:247) finished in 0.049 s
2020-04-04 18:56:26,250 INFO  [task-result-getter-0] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2020-04-04 18:56:26,250 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - looking for newly runnable stages
2020-04-04 18:56:26,252 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - running: Set()
2020-04-04 18:56:26,252 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - waiting: Set(ResultStage 11)
2020-04-04 18:56:26,252 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - failed: Set()
2020-04-04 18:56:26,253 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting ResultStage 11 (MapPartitionsRDD[12] at mapToPair at TFICF.java:256), which has no missing parents
2020-04-04 18:56:26,256 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_9 stored as values in memory (estimated size 3.4 KB, free 327.1 KB)
2020-04-04 18:56:26,259 INFO  [dag-scheduler-event-loop] storage.MemoryStore (Logging.scala:logInfo(58)) - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2011.0 B, free 329.1 KB)
2020-04-04 18:56:26,261 INFO  [dispatcher-event-loop-7] storage.BlockManagerInfo (Logging.scala:logInfo(58)) - Added broadcast_9_piece0 in memory on localhost:41699 (size: 2011.0 B, free: 511.1 MB)
2020-04-04 18:56:26,262 INFO  [dag-scheduler-event-loop] spark.SparkContext (Logging.scala:logInfo(58)) - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2020-04-04 18:56:26,263 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[12] at mapToPair at TFICF.java:256)
2020-04-04 18:56:26,263 INFO  [dag-scheduler-event-loop] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Adding task set 11.0 with 4 tasks
2020-04-04 18:56:26,265 INFO  [dispatcher-event-loop-8] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 0.0 in stage 11.0 (TID 18, localhost, partition 0,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:26,267 INFO  [dispatcher-event-loop-8] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 1.0 in stage 11.0 (TID 19, localhost, partition 1,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:26,268 INFO  [dispatcher-event-loop-8] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 2.0 in stage 11.0 (TID 20, localhost, partition 2,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:26,269 INFO  [dispatcher-event-loop-8] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Starting task 3.0 in stage 11.0 (TID 21, localhost, partition 3,NODE_LOCAL, 1941 bytes)
2020-04-04 18:56:26,271 INFO  [Executor task launch worker-3] executor.Executor (Logging.scala:logInfo(58)) - Running task 0.0 in stage 11.0 (TID 18)
2020-04-04 18:56:26,271 INFO  [Executor task launch worker-2] executor.Executor (Logging.scala:logInfo(58)) - Running task 3.0 in stage 11.0 (TID 21)
2020-04-04 18:56:26,271 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Running task 1.0 in stage 11.0 (TID 19)
2020-04-04 18:56:26,275 INFO  [Executor task launch worker-2] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 3 non-empty blocks out of 4 blocks
2020-04-04 18:56:26,275 INFO  [Executor task launch worker-2] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 0 ms
2020-04-04 18:56:26,271 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Running task 2.0 in stage 11.0 (TID 20)
2020-04-04 18:56:26,277 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 3 non-empty blocks out of 4 blocks
2020-04-04 18:56:26,277 INFO  [Executor task launch worker-3] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 2 non-empty blocks out of 4 blocks
2020-04-04 18:56:26,277 INFO  [Executor task launch worker-0] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 0 ms
2020-04-04 18:56:26,278 INFO  [Executor task launch worker-3] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 1 ms
2020-04-04 18:56:26,279 INFO  [Executor task launch worker-2] executor.Executor (Logging.scala:logInfo(58)) - Finished task 3.0 in stage 11.0 (TID 21). 1381 bytes result sent to driver
2020-04-04 18:56:26,280 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Getting 3 non-empty blocks out of 4 blocks
2020-04-04 18:56:26,280 INFO  [Executor task launch worker-1] storage.ShuffleBlockFetcherIterator (Logging.scala:logInfo(58)) - Started 0 remote fetches in 1 ms
2020-04-04 18:56:26,281 INFO  [task-result-getter-2] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 3.0 in stage 11.0 (TID 21) in 11 ms on localhost (1/4)
2020-04-04 18:56:26,283 INFO  [Executor task launch worker-3] executor.Executor (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 11.0 (TID 18). 1316 bytes result sent to driver
2020-04-04 18:56:26,286 INFO  [task-result-getter-3] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 0.0 in stage 11.0 (TID 18) in 21 ms on localhost (2/4)
2020-04-04 18:56:26,288 INFO  [Executor task launch worker-1] executor.Executor (Logging.scala:logInfo(58)) - Finished task 2.0 in stage 11.0 (TID 20). 1430 bytes result sent to driver
2020-04-04 18:56:26,289 INFO  [task-result-getter-1] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 2.0 in stage 11.0 (TID 20) in 22 ms on localhost (3/4)
2020-04-04 18:56:26,302 INFO  [Executor task launch worker-0] executor.Executor (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 11.0 (TID 19). 1526 bytes result sent to driver
2020-04-04 18:56:26,305 INFO  [task-result-getter-0] scheduler.TaskSetManager (Logging.scala:logInfo(58)) - Finished task 1.0 in stage 11.0 (TID 19) in 39 ms on localhost (4/4)
2020-04-04 18:56:26,305 INFO  [task-result-getter-0] scheduler.TaskSchedulerImpl (Logging.scala:logInfo(58)) - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2020-04-04 18:56:26,306 INFO  [dag-scheduler-event-loop] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - ResultStage 11 (collect at TFICF.java:268) finished in 0.042 s
2020-04-04 18:56:26,308 INFO  [main] scheduler.DAGScheduler (Logging.scala:logInfo(58)) - Job 5 finished: collect at TFICF.java:268, took 0.141562 s
-------Contents of tficfRDD-------
doc1@Lorem	0.10684910910366296
doc1@dolor	0.10684910910366296
doc1@ipsum	0.1166450426074421
doc1@sit	0.10684910910366296
doc2@Vituperata	0.10684910910366296
doc2@at	0.10684910910366296
doc2@incorrupte	0.10684910910366296
doc2@ipsum	0.04434638704255661
doc2@pro	0.10684910910366296
doc2@quo	0.10684910910366296
doc3@Has	0.12637567304702957
doc3@disputationi	0.12637567304702957
doc3@id	0.12637567304702957
doc3@persius	0.12637567304702957
doc3@simul	0.12637567304702957
--------------------------------
2020-04-04 18:56:26,315 INFO  [Thread-3] spark.SparkContext (Logging.scala:logInfo(58)) - Invoking stop() from shutdown hook
2020-04-04 18:56:26,364 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2020-04-04 18:56:26,364 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2020-04-04 18:56:26,365 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/api,null}
2020-04-04 18:56:26,366 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/,null}
2020-04-04 18:56:26,366 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/static,null}
2020-04-04 18:56:26,367 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2020-04-04 18:56:26,367 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2020-04-04 18:56:26,368 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2020-04-04 18:56:26,369 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2020-04-04 18:56:26,369 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2020-04-04 18:56:26,370 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2020-04-04 18:56:26,370 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2020-04-04 18:56:26,371 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2020-04-04 18:56:26,371 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2020-04-04 18:56:26,371 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2020-04-04 18:56:26,372 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2020-04-04 18:56:26,372 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2020-04-04 18:56:26,372 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2020-04-04 18:56:26,372 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2020-04-04 18:56:26,372 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2020-04-04 18:56:26,373 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2020-04-04 18:56:26,373 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2020-04-04 18:56:26,373 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2020-04-04 18:56:26,373 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2020-04-04 18:56:26,374 INFO  [Thread-3] handler.ContextHandler (ContextHandler.java:doStop(843)) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2020-04-04 18:56:26,428 INFO  [Thread-3] ui.SparkUI (Logging.scala:logInfo(58)) - Stopped Spark web UI at http://10.4.1.31:4040
2020-04-04 18:56:26,450 INFO  [dispatcher-event-loop-3] spark.MapOutputTrackerMasterEndpoint (Logging.scala:logInfo(58)) - MapOutputTrackerMasterEndpoint stopped!
2020-04-04 18:56:26,464 INFO  [Thread-3] storage.MemoryStore (Logging.scala:logInfo(58)) - MemoryStore cleared
2020-04-04 18:56:26,465 INFO  [Thread-3] storage.BlockManager (Logging.scala:logInfo(58)) - BlockManager stopped
2020-04-04 18:56:26,469 INFO  [Thread-3] storage.BlockManagerMaster (Logging.scala:logInfo(58)) - BlockManagerMaster stopped
2020-04-04 18:56:26,473 INFO  [dispatcher-event-loop-8] scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint (Logging.scala:logInfo(58)) - OutputCommitCoordinator stopped!
2020-04-04 18:56:26,478 INFO  [Thread-3] spark.SparkContext (Logging.scala:logInfo(58)) - Successfully stopped SparkContext
2020-04-04 18:56:26,479 INFO  [Thread-3] util.ShutdownHookManager (Logging.scala:logInfo(58)) - Shutdown hook called
2020-04-04 18:56:26,480 INFO  [Thread-3] util.ShutdownHookManager (Logging.scala:logInfo(58)) - Deleting directory /tmp/spark-afba352f-d46f-49ad-a180-2e060112b88f/httpd-9de3de33-cdf3-48ab-a841-b7224e39f6bd
2020-04-04 18:56:26,482 INFO  [Thread-3] util.ShutdownHookManager (Logging.scala:logInfo(58)) - Deleting directory /tmp/spark-afba352f-d46f-49ad-a180-2e060112b88f
2020-04-04 18:56:26,490 INFO  [sparkDriverActorSystem-akka.actor.default-dispatcher-4] remote.RemoteActorRefProvider$RemotingTerminator (Slf4jLogger.scala:apply$mcV$sp(74)) - Shutting down remote daemon.
2020-04-04 18:56:26,494 INFO  [sparkDriverActorSystem-akka.actor.default-dispatcher-4] remote.RemoteActorRefProvider$RemotingTerminator (Slf4jLogger.scala:apply$mcV$sp(74)) - Remote daemon shut down; proceeding with flushing remote transports.
2020-04-04 18:56:26,548 INFO  [sparkDriverActorSystem-akka.actor.default-dispatcher-4] remote.RemoteActorRefProvider$RemotingTerminator (Slf4jLogger.scala:apply$mcV$sp(74)) - Remoting shut down.
